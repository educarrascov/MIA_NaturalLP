{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"asr-tts.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOH9nx4NOuA2XP9MC8ZDDY+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EN8dL79FN4CD"},"source":["**RECONOCIMIENTO Y SÍNTESIS DE VOZ**\n","\n","*John Atkinson*\n","\n","Este programa utiliza servicios pre-entrenados de Google para *reconocimiento automático de  voz* (ASR) y *síntesis de texto a voz* (TTS) en Español.\n","\n","*   El módulo de ASR utiliza el servicio [SpeechRecognition](https://realpython.com/python-speech-recognition/). Note que *Google Colab* no puede procesar el dispositivo de audio directamente (i.e., micrófono) por lo que se realizó unos pequeños ajustes invocando a rutinas en JavaScript.\n","\n","*   El módulo de TTS utiliza el servicio [gTTS](https://gtts.readthedocs.io/en/latest/module.html).\n","\n","Primero, necesitamos instalar algunos paquetes:"]},{"cell_type":"code","metadata":{"id":"Xff_tQF9N6YC"},"source":["!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n","!pip install speechrecognition\n","!pip install PyAudio\n","!pip -q install pydub\n","!pip install gtts\n","!pip install pygobject"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xKgZABDp4BQM"},"source":["Luego, importamos algunas bibliotecas para manejo de audio, reconocimient y síntesis:"]},{"cell_type":"code","metadata":{"id":"mPaviz36PGHQ"},"source":["import speech_recognition as sr \n","from pydub import AudioSegment\n","from IPython.display import Javascript, Audio\n","from google.colab import output\n","from base64 import b64decode\n","from io import BytesIO\n","import subprocess\n","import re\n","from gtts import gTTS "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DNslrRTu4Lnf"},"source":["Dado que nuestro programa está corriendo en *Google Colab*, el manejo de audio no es tan directo como cuando el programa se encuentra en nuestro propio computador ya que accede directamente a los dispositivos de audio (micrófono, parlantes). \n","\n","Para resolver este problema, realizamos dos pasos:\n","1. Grabar el audio y almacenarlo en un archivo de sonido (se debe utilizar *JavaScript*).\n","2. Realizar el reconocimiento de voz a partir del audio previamente grabado.\n","\n","Para esto,  definimos la función **Grabar()**, que graba un audio utilizando un código JavaScript en el archivo temporal \"*out00.wav*\":"]},{"cell_type":"code","metadata":{"id":"F2miplER6CCr"},"source":["RECORD = \"\"\"\n","const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n","const b2text = blob => new Promise(resolve => {\n","  const reader = new FileReader()\n","  reader.onloadend = e => resolve(e.srcElement.result)\n","  reader.readAsDataURL(blob)\n","})\n","var record = time => new Promise(async resolve => {\n","  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n","  recorder = new MediaRecorder(stream)\n","  chunks = []\n","  recorder.ondataavailable = e => chunks.push(e.data)\n","  recorder.start()\n","  await sleep(time)\n","  recorder.onstop = async ()=>{\n","    blob = new Blob(chunks)\n","    text = await b2text(blob)\n","    resolve(text)\n","  }\n","  recorder.stop()\n","})\n","\"\"\"\n","\n","def Grabar(sec=5):\n","  display(Javascript(RECORD))\n","  s = output.eval_js('record(%d)' % (sec*1000))\n","  b = b64decode(s.split(',')[1])\n","  with open('audio.webm','wb') as f:\n","    f.write(b)\n","  command = ['ffmpeg', '-i', 'audio.webm', '-f', 'segment', '-segment_time', '100', 'out%02d.wav']\n","  subprocess.run(command,stdout=subprocess.PIPE,stdin=subprocess.PIPE)\n","  return('out00.wav')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ku8eSZP4tECS"},"source":["Definimos la función **ASR()** que realiza el reconocimiento de voz propiamente tal, y que utiliza el módulo de grabado de audio, especificado previamente:"]},{"cell_type":"code","metadata":{"id":"CQl_DB7JYWz1"},"source":["def ASR():\n","    texto_reconocido=\"\"\n","    print(\"Comience a hablar..\")\n","    # Si ejecutará el programa en su computador (NO Colab), simplemente\n","    # reemplace las líneas desde \"WAVES=..\"  hasta \"try:\" por las siguientes:\n","    #r = sr.Recognizer()                                                                                   \n","    #with sr.Microphone() as source:                                                                     \n","    #   print(\".\")\n","    #   audio = r.listen(source)   \n","    #   print(\"..\")\n","    #try: \n","    WAVES = Grabar()\n","    fuente = sr.AudioFile(WAVES)\n","    r = sr.Recognizer()\n","    with fuente as source:\n","         audio = r.record(source)                                 \n","    try:\n","         texto_reconocido = r.recognize_google(audio, language='es-es')\n","    except sr.UnknownValueError:\n","       print(\"No entendi el audio\")\n","    return(texto_reconocido)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7hadef9Vt8-G"},"source":["Luego,  definimos la función  **TTS(texto)**, que realiza la síntesis de voz en Español utilizando el método **gTTS(..)**,  a partir de un **texto**, utilizando modelos *fonéticos* pre-entrenados:"]},{"cell_type":"code","metadata":{"id":"5Y6AToN6uLug"},"source":["def TTS(texto):\n","  sound_file = 'tmp.wav'\n","  tts = gTTS(texto, lang=\"es\")\n","  tts.save(sound_file) \n","  display(Audio(sound_file,autoplay=True))  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQDABHpTuXiU"},"source":["Finalmente, hacemos una prueba del ASR y TTS desde el programa principal. Para esto, buscamos si en la voz reconocida del usuario aparece la palabra \"*auto*\" en algún lugar:"]},{"cell_type":"code","metadata":{"id":"fWDpS8qGOV4h"},"source":["texto = ASR()\n","print(\"Dijiste: \",texto)\n","calce = re.search(\"auto\",texto)\n","if calce != None:\n","    TTS(\"Usted necesita comprar un auto..\")"],"execution_count":null,"outputs":[]}]}