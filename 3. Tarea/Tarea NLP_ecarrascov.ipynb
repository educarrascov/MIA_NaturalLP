{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b7e1f8-0c4d-426d-a0d6-f6fe6d719a5c",
   "metadata": {
    "id": "f9b7e1f8-0c4d-426d-a0d6-f6fe6d719a5c"
   },
   "source": [
    "## **Eduardo Carrasco Vidal** <img src=\"img/logo.png\" align=\"right\" style=\"width: 120px;\"/>\n",
    "\n",
    "**Magister en Inteligencia Artificial, Universidad Adolfo Ibáñez.**\n",
    "\n",
    "**Profesor:** John Atkinson.\n",
    "**Curso:** Procesamiento del Leguaje Natural (Natural Language Processing).\n",
    "\n",
    "Enlace al repositorio del alumno en [GitHub](https://github.com/educarrascov/MIA_NaturalLP) _@educarrascov_\n",
    "\n",
    "![Python](https://img.shields.io/badge/python-%2314354C.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2D0t5B2Y1-5M",
   "metadata": {
    "id": "2D0t5B2Y1-5M"
   },
   "source": [
    "## OBJETIVO:\n",
    "\n",
    "El objetivo de esta tarea es entender y aplicar conceptos básicos de Procesamiento de Lenguaje Natural (NLP) y modelos de Word Embeddings para abordar una actividad simple de generación automática de resúmenes **(Summarization)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3dd198-d844-4cc5-99c7-a3a89b7cf44e",
   "metadata": {},
   "source": [
    "## DESCRIPCIÓN:\n",
    "\n",
    "Muchas decisiones que se toman en diversos ámbitos productivos dependen de la síntesis de mucha documentación que se encuentra en la Web. Sin embargo, la cantidad de información disponible es tal que es prácticamente imposible resumir toda la información en forma manual. El problema es que sin una síntesis o resumen, puede tomar mucho tiempo entender algún documento, artículo o reporte, de ahí es que se requiere de métodos automatizados. El generador más simple de resúmenes (aka. Summarizer) es un algoritmo que determina la importancia de las oraciones del texto, y luego extrae aquellas que son más importantes y que son coherentes entre ellas, produciendo el resumen final.\n",
    "\n",
    "Una forma de abordar esta actividad de summarization consiste en utilizar modelos de word embeddings tales como Word2Vec. Luego, se puede generar las representaciones semánticas (embeddings) de cada oración de un texto completo. Con dichos embeddings se puede determinar la importancia de cada oración en el texto, y luego extraer las más importantes para ir agregándolas al resumen final.\n",
    "\n",
    "Con el fin de que el texto resumido final sea coherente, el objetivo es agregar oraciones que son importantes pero que a la vez tienen una alta similitud con las que estaban hasta ahora en el resumen. Este último paso asegura que las oraciones que se producen en el resumen estén conectadas lógicamente con las oraciones previas. Esta característica lingüística de los textos comprensibles se denomina coherencia local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3065cf",
   "metadata": {
    "id": "7f3065cf"
   },
   "source": [
    "### **CLASIFICACIÓN DE SENTIMIENTOS CON LSA**\n",
    "\n",
    "Se utiliza  *Análisis Semántico Latente*  (LSA) para generar **embeddings** que permitan realizar posteriormente una actividad de clasificación de sentimientos, mediante un modelo de clasificación **Bayesiano Gausiano**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c06c21-04ea-413c-8e58-c9f88fa84253",
   "metadata": {
    "id": "11c06c21-04ea-413c-8e58-c9f88fa84253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es_core_news_sm\n",
      "  Using cached es_core_news_sm-3.1.0-py3-none-any.whl (13.7 MB)\n",
      "Collecting spacy<3.2.0,>=3.1.0\n",
      "  Downloading spacy-3.1.6.tar.gz (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Using cached thinc-8.0.17-cp39-cp39-macosx_11_0_arm64.whl (586 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (4.64.1)\n",
      "Requirement already satisfied: jinja2 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.23.2)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.7-cp39-cp39-macosx_11_0_arm64.whl (31 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp39-cp39-macosx_11_0_arm64.whl (19 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.9-cp39-cp39-macosx_11_0_arm64.whl (1.1 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.28.1)\n",
      "Collecting click<8.1.0\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Using cached spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.8-cp39-cp39-macosx_11_0_arm64.whl (101 kB)\n",
      "Requirement already satisfied: setuptools in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (65.5.1)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.2-py3-none-any.whl (42 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Using cached srsly-2.4.5-cp39-cp39-macosx_11_0_arm64.whl (489 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.0.9)\n",
      "Collecting smart-open<6.0.0,>=5.2.1\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->es_core_news_sm) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/educarrascovidal/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.1.1)\n",
      "Building wheels for collected packages: spacy\n",
      "  Building wheel for spacy (pyproject.toml) ... \u001b[?25l/"
     ]
    }
   ],
   "source": [
    "pip install es_core_news_sm #en caso de correrlo en colab, se debe instalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b090278",
   "metadata": {
    "id": "4b090278"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'es_core_news_sm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mes_core_news_sm\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'es_core_news_sm'"
     ]
    }
   ],
   "source": [
    "import es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f7970",
   "metadata": {
    "id": "0a9f7970"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import regex\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import svd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c98e2e6",
   "metadata": {
    "id": "5c98e2e6"
   },
   "source": [
    "Se definen las siguientes funciones:\n",
    "\n",
    "**CrearModeloLSA(textos,dim,NombreModelo)**, que utiliza LSA para crear un *espacio semántico* de dimensiones reducidas (i.e., modelo vectorial que representa documentos y palabras), que se graba y luego puede ser cargado por otros programas. \n",
    "\n",
    "La función recibe la lista de documentos pre-procesados (**textos**), el número de dimensiones a reducir (**dim**) vía SVD, y el nombre de la carpeta donde se grabará el modelo (**NombreModelo**), en este caso será destinada como _mi_lsa_.\n",
    "\n",
    "LSA utiliza la *descomposición de valores singulares* (SVD) para descomponer la matriz de frecuencias original vía **TfidfVectorizer** en tres matrices: $U$, $\\Sigma$ y $V^T$. Luego, las nuevas representaciones vectoriales en dimensiones reducidas (**dim**)  se reconstruyen  como:\n",
    "\n",
    "*   Representación de  términos: $U(dim) *  \\Sigma(dim)$\n",
    "\n",
    "*   Representación  de documentos: $\\Sigma(dim) * V^T(dim)$\n",
    "\n",
    "De igual manera, es importante definir funciones que permitan:\n",
    "- Grabar el modelo **GrabarModeloLSA(NombreModelo,Sigma,terms,docs, vocab)**. \n",
    "- Cargar el modelo **CargarModeloLSA(NombreModelo)**.\n",
    "- Crear un diccionario **CrearDiccionario(lista_vectores,claves)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76370ad6",
   "metadata": {
    "id": "76370ad6"
   },
   "outputs": [],
   "source": [
    "def CrearModeloLSA(textos,dim,NombreModelo):\n",
    "  MatrizFrec = TfidfVectorizer()\n",
    "  tf = MatrizFrec.fit_transform(textos).T\n",
    "  U, Sigma, VT = svd(tf.toarray())\n",
    "  # Se realiza producto punto de matrices con las nuevas dimensiones\n",
    "  terms = np.dot(U[:,:dim], np.diag(Sigma[:dim]))\n",
    "  docs  = np.dot(np.diag(Sigma[:dim]), VT[:dim, :]).T \n",
    "  vocab = MatrizFrec.get_feature_names()\n",
    "  GrabarModeloLSA(NombreModelo, Sigma, terms, docs, vocab)\n",
    "\n",
    "def GrabarModeloLSA(NombreModelo,Sigma,terms,docs, vocab):\n",
    "   existe = os.path.isdir(NombreModelo)\n",
    "   if not existe:\n",
    "       os.mkdir(NombreModelo)\n",
    "   joblib.dump(Sigma,   NombreModelo +\"/\"+'sigma.pkl') \n",
    "   joblib.dump(terms,   NombreModelo +\"/\"+'terms.pkl') \n",
    "   joblib.dump(docs,    NombreModelo +\"/\"+'docs.pkl') \n",
    "   joblib.dump(vocab,   NombreModelo +\"/\"+'vocab.pkl') \n",
    "\n",
    "def CargarModeloLSA(NombreModelo):\n",
    "    terms   = joblib.load(NombreModelo+\"/\"+'terms.pkl')\n",
    "    vocab   = joblib.load(NombreModelo+\"/\"+'vocab.pkl')\n",
    "    modelo =  CrearDiccionario(terms,vocab)\n",
    "    return(modelo)\n",
    "def CrearDiccionario(lista_vectores,claves):\n",
    "   dicc = {}\n",
    "   for  v in range(0,len(claves)):\n",
    "      dicc[claves[v]] = lista_vectores[v]\n",
    "   return(dicc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1388504",
   "metadata": {
    "id": "d1388504"
   },
   "source": [
    "Un aspecto importante al utilizar LSA es determinar cuál es el número óptimo de dimensiones a reducir. Esto depende del tamaño del corpus utiizado para construir el modelo:\n",
    "\n",
    "1.   Si el tamaño es muy grande (i.e., varios GigaBytes de texto), lo adecuado es utilizar entre 200 a 300 dimensiones.\n",
    "2.   Si el tamaño  es pequeño, se puede elegir el número de dimensiones como el número de valores singulares de la matriz $\\Sigma$) que maximice la *importancia* (descartando el primer valor pues corelaciona con el largo del corpus). La importancia de un valor singular $x$ es simplemente $x^2$.\n",
    "\n",
    "Para visualizar la importancia de los valores singulares, podemos definir  la función **GraficarImportancia($\\Sigma$)**, que grafica los valores singulares (i.e., dimensiones) versus importancia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b2a13",
   "metadata": {
    "id": "3d5b2a13"
   },
   "outputs": [],
   "source": [
    "def GraficarImportancia(Sigma):   \n",
    "    NumValores = np.arange(len(Sigma))\n",
    "    Importancia = [x**2 for x in Sigma]\n",
    "    plt.bar(NumValores,Importancia)\n",
    "    plt.ylabel('Importancia')\n",
    "    plt.xlabel('Valores Singulares')\n",
    "    plt.title('Importancia de Valores Singulares en SVD')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb97fd91-813f-4e4f-86f6-0b2ed9d30766",
   "metadata": {},
   "source": [
    "funciones de preprocesamiento / procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b593fc4",
   "metadata": {
    "id": "7b593fc4"
   },
   "outputs": [],
   "source": [
    " def PreProcesar(textos):\n",
    "    texto_limpio = []\n",
    "    for texto in textos:  \n",
    "        texto = Lematizar(texto)     \n",
    "        texto = EliminaNumeroYPuntuacion(texto)      \n",
    "        texto_limpio.append(texto)\n",
    "    return(texto_limpio)\n",
    "\n",
    "def Lematizar(oracion):\n",
    "   doc = nlp(oracion)\n",
    "   lemas = [token.lemma_ for token in doc]\n",
    "   return(\" \".join(lemas))  \n",
    "\n",
    "def EliminaNumeroYPuntuacion(oracion):\n",
    "    string_numeros = regex.sub(r'[\\”\\“\\¿\\°\\d+]','', oracion)\n",
    "    return ''.join(c for c in string_numeros if c not in punctuation)\n",
    "\n",
    "def Tokenizar(oracion):\n",
    "    doc = nlp(oracion)\n",
    "    tokens = [palabra.text for palabra in doc]\n",
    "    return(tokens)\n",
    "\n",
    "def CrearCorpus(path):\n",
    "  directorio = os.listdir(path)\n",
    "  corpus = []\n",
    "  doc_id = []  \n",
    "  for NombreArchivo  in directorio:\n",
    "     try:\n",
    "          texto = open(path+NombreArchivo,'r',encoding=\"utf-8\").read()\n",
    "          corpus.append(texto)\n",
    "          doc_id.append(NombreArchivo)\n",
    "     except IsADirectoryError:\n",
    "          texto = \"\"\n",
    "  return(corpus,doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dad95e",
   "metadata": {
    "id": "09dad95e"
   },
   "source": [
    "Una vez que generamos las nuevas representaciones vectoriales para documentos y términos, podríamos utilizar dichos  vectores para realizar diversas tareas tales como clustering, clasificación, comparación de documentos, etc.\n",
    "\n",
    "Como ejemplo, definamos la función **GraficarVectores(vocab,vectores)**, que toma vectores de documentos (o palabras), y el vocabulario, y grafica cada uno de los elementos en un gráfico 2-dimensional. Dado que los vectores contienen más de 2 dimensiones, en este ejemplo, sólo tomamos las 2 primeras. \n",
    "\n",
    "El gráfico le permitirá visualizar espacialmente la *cercanía* que existe entre documentos para posteriores análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1697008",
   "metadata": {
    "id": "f1697008"
   },
   "outputs": [],
   "source": [
    "def GraficarVectores(vocab,vectores):\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in vectores:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])   \n",
    "    plt.figure(figsize=(7, 7))   \n",
    "    plt.title(\"Distribución Espacial de Documentos\")\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(vocab[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033fbd7a",
   "metadata": {
    "id": "033fbd7a"
   },
   "source": [
    "Los vectores para documentos o palabras están indexados por posición y no por nombre, lo que podría dificultad el acceso. \n",
    "\n",
    "Para mejorar esto, podemos definir la función **CrearDiccionario(Vectores,vocabulario)**, que dado un conjunto de **vectores** (de documentos o palabras) y un **vocabulario**, genera un nuevo arreglo donde el índice es el nombre correspondiente: una palabra en el caso de vectores de palabras o un nombre de documento en el caso de vectores de documentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402f37b",
   "metadata": {
    "id": "f402f37b"
   },
   "outputs": [],
   "source": [
    "def ObtenerEmbeddingOracion(modelo, dim, oracion):\n",
    "   Lista_enbeddings = []\n",
    "   Tokens = Tokenizar(oracion)\n",
    "   for w in Tokens:\n",
    "       # Verificar que la palabra w exista en el modelo\n",
    "       try:\n",
    "           modelo[w]\n",
    "       except KeyError:\n",
    "           continue\n",
    "       # Obtener vector de la palabra w\n",
    "       embedding = modelo[w]\n",
    "       Lista_enbeddings.append(embedding)\n",
    "   embedding_palabras = np.array(Lista_enbeddings)\n",
    "   if (len(embedding_palabras) > 0):\n",
    "        embedding_oracion = embedding_palabras.mean(axis=0)\n",
    "   else:\n",
    "        embedding_oracion = np.zeros(dim)\n",
    "   return(embedding_oracion) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fee028",
   "metadata": {
    "id": "42fee028"
   },
   "source": [
    "Ahora, realizamos nuestro programa principal donde ajustamos la ruta donde se encuentran los documentos del corpus e inicializamos los modelos de lenguaje, en este caso la ruta está referenciada a la misma carpeta que contiene la tarea **(DiscursosOriginales)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6002ced",
   "metadata": {
    "id": "a6002ced"
   },
   "outputs": [],
   "source": [
    "PATH = \"DiscursosOriginales/\"\n",
    "nlp = es_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b88aa-5aab-4dfa-bb89-8b7f5302eb9c",
   "metadata": {},
   "source": [
    "Por último, previo a iniciar el modelado, se debe generar un set de Training y otro de Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a296b",
   "metadata": {
    "id": "f25a296b"
   },
   "outputs": [],
   "source": [
    "# Preparando discursos de training y test\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "def SepararDiscursosTrainYtest(test_size=0.25):\n",
    "    shutil.rmtree(PATH+'Train', ignore_errors=True)\n",
    "    shutil.rmtree(PATH+'Test', ignore_errors=True)\n",
    "    X = y = os.listdir(PATH)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "    os.mkdir(PATH+'Train')\n",
    "    os.mkdir(PATH+'Test')\n",
    "    for x in X_train:\n",
    "        shutil.copyfile(PATH+x, PATH+'Train/'+x)\n",
    "    for x in X_test:\n",
    "        shutil.copyfile(PATH+x, PATH+'Test/'+x)\n",
    "SepararDiscursosTrainYtest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a44bb",
   "metadata": {
    "id": "911a44bb"
   },
   "source": [
    "A partir de lo anterio, se genera el corpus (texto) desde la carpeta DiscursosOriginales, de manera de generar un espacio semántico con el modelo LSA grabandolo en una carpeta _mi_lsa_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20b13f",
   "metadata": {
    "executionInfo": {
     "elapsed": 1467,
     "status": "ok",
     "timestamp": 1632144025053,
     "user": {
      "displayName": "John Atkinson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg2bkbkmnbTiDRGZ-S-AD9kxpASaoVjtEAIDefWcA=s64",
      "userId": "05558035681160401394"
     },
     "user_tz": 180
    },
    "id": "de20b13f",
    "outputId": "44d27ff9-da98-4e5a-993e-6e2bf4629ae4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dim =  200\n",
    "if os.path.isdir(\"mi_lsa\"):\n",
    "    modeloLSA = CargarModeloLSA(\"mi_lsa\")\n",
    "else:\n",
    "    corpus, lista_docs = CrearCorpus(PATH+'Train/')\n",
    "    textos  = PreProcesar(corpus)\n",
    "    CrearModeloLSA(textos,dim,\"mi_lsa\")\n",
    "    modeloLSA = CargarModeloLSA(\"mi_lsa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f715c-5431-4659-af54-4b936963858d",
   "metadata": {},
   "source": [
    "Efectuado el modelado, es importante seleccionar el discurso sobre el cual se requiere efectuar la **summarizació**, para esto, se despliega objeto sea seleccionado en forma manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c79a3",
   "metadata": {
    "id": "014c79a3",
    "outputId": "09042a65-6e2f-4bfb-cd65-ec9679b83821",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['95948.txt',\n",
       " '98069.txt',\n",
       " '90073.txt',\n",
       " '89375.txt',\n",
       " '91144.txt',\n",
       " '100227.txt',\n",
       " '102066.txt',\n",
       " '135819.txt',\n",
       " '100033.txt',\n",
       " '80384.txt',\n",
       " '84089.txt',\n",
       " '97896.txt',\n",
       " '100296.txt',\n",
       " '93927.txt',\n",
       " '152588.txt',\n",
       " '86848.txt',\n",
       " '75561.txt',\n",
       " '153298.txt',\n",
       " '164594.txt',\n",
       " '74634.txt',\n",
       " '75019.txt',\n",
       " '93848.txt',\n",
       " '101766.txt',\n",
       " '151434.txt',\n",
       " '100172.txt',\n",
       " '74598.txt',\n",
       " '81222.txt',\n",
       " '78838.txt',\n",
       " '100547.txt',\n",
       " '85341.txt',\n",
       " '73772.txt',\n",
       " '81517.txt',\n",
       " '101255.txt',\n",
       " '90435.txt',\n",
       " '92554.txt',\n",
       " '71901.txt',\n",
       " '80001.txt',\n",
       " '138176.txt',\n",
       " '149939.txt',\n",
       " '93108.txt',\n",
       " '81469.txt',\n",
       " '76217.txt',\n",
       " '151297.txt',\n",
       " '81311.txt',\n",
       " '88568.txt',\n",
       " '96720.txt',\n",
       " '86407.txt',\n",
       " '83512.txt',\n",
       " '85835.txt',\n",
       " '75320.txt',\n",
       " '74712.txt',\n",
       " '102687.txt',\n",
       " '164282.txt',\n",
       " '151972.txt',\n",
       " '72170.txt',\n",
       " '135207.txt',\n",
       " '148650.txt',\n",
       " '135757.txt',\n",
       " '93588.txt',\n",
       " '91265.txt',\n",
       " '94214.txt',\n",
       " '90274.txt',\n",
       " '84826.txt',\n",
       " '97684.txt',\n",
       " '150341.txt',\n",
       " '99397.txt',\n",
       " '101337.txt',\n",
       " '90064.txt',\n",
       " '91320.txt',\n",
       " '138138.txt',\n",
       " '153186.txt',\n",
       " '81631.txt',\n",
       " '99070.txt',\n",
       " '78127.txt',\n",
       " '93222.txt',\n",
       " '74351.txt',\n",
       " '100260.txt',\n",
       " '164847.txt',\n",
       " '100178.txt',\n",
       " '96579.txt',\n",
       " '87336.txt',\n",
       " '103359.txt',\n",
       " '150322.txt',\n",
       " '95887.txt',\n",
       " '95630.txt',\n",
       " '95253.txt',\n",
       " '75444.txt',\n",
       " '152206.txt',\n",
       " '89907.txt',\n",
       " '72231.txt',\n",
       " '87594.txt',\n",
       " '152358.txt',\n",
       " '102960.txt',\n",
       " '78636.txt',\n",
       " '81050.txt',\n",
       " '150300.txt',\n",
       " '84780.txt',\n",
       " '81872.txt',\n",
       " '90825.txt',\n",
       " '72110.txt',\n",
       " '71862.txt',\n",
       " '149691.txt',\n",
       " '91411.txt',\n",
       " '89879.txt',\n",
       " '81668.txt',\n",
       " '73260.txt',\n",
       " '98143.txt',\n",
       " '80685.txt',\n",
       " '102791.txt',\n",
       " '165240.txt',\n",
       " '74298.txt',\n",
       " '74929.txt',\n",
       " '164199.txt',\n",
       " '135074.txt',\n",
       " '94660.txt',\n",
       " '79291.txt',\n",
       " '91886.txt',\n",
       " '81762.txt',\n",
       " '96193.txt',\n",
       " '135058.txt',\n",
       " '152256.txt',\n",
       " '90815.txt',\n",
       " '73274.txt',\n",
       " '93252.txt',\n",
       " '91667.txt',\n",
       " '83405.txt',\n",
       " '86780.txt',\n",
       " '95488.txt',\n",
       " '82894.txt',\n",
       " '86301.txt',\n",
       " '73515.txt',\n",
       " '84260.txt',\n",
       " '89884.txt',\n",
       " '85214.txt',\n",
       " '85228.txt',\n",
       " '95583.txt',\n",
       " '76776.txt',\n",
       " '136809.txt',\n",
       " '80522.txt',\n",
       " '83231.txt',\n",
       " '88676.txt',\n",
       " '89628.txt',\n",
       " '98482.txt',\n",
       " '150450.txt',\n",
       " '98621.txt',\n",
       " '165648.txt',\n",
       " '90183.txt',\n",
       " '80908.txt',\n",
       " '153144.txt',\n",
       " '165020.txt',\n",
       " '79915.txt',\n",
       " '82001.txt',\n",
       " '137927.txt',\n",
       " '79722.txt',\n",
       " '82031.txt',\n",
       " '101452.txt',\n",
       " '73705.txt',\n",
       " '88165.txt',\n",
       " '95530.txt',\n",
       " '82128.txt',\n",
       " '150995.txt',\n",
       " '152294.txt',\n",
       " '149210.txt',\n",
       " '136176.txt',\n",
       " '97464.txt',\n",
       " '91790.txt',\n",
       " '84916.txt',\n",
       " '98892.txt',\n",
       " '80818.txt',\n",
       " '77233.txt',\n",
       " '90940.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos_test = os.listdir(PATH+'Test/')\n",
    "textos_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e76e2-50ae-454c-ac5f-b0adcf081144",
   "metadata": {},
   "source": [
    "Del listado anterior, se decidió seleccionar el **discurso 100172.txt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a89ee4",
   "metadata": {
    "id": "41a89ee4"
   },
   "outputs": [],
   "source": [
    "texto = open(PATH+'Test/100172.txt','r',encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae643e",
   "metadata": {
    "id": "c2ae643e",
    "outputId": "e0e72562-c9d9-4bf2-b042-555cf9427d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muy buenas tardes:\n",
      "\n",
      " \n",
      "\n",
      "Señor Ministro, señor Intendente, señor Senador, señor Presidente del Directorio, señor Alcalde; y quiero entregar un saludo muy especial a Nelson Pizarro, Presidente Ejecutivo de Codelco. Y, como Presidente de todos los chilenos, yo sé que interpreto a todos mis compatriotas al agradecerle, como lo hice en privado, muy sinceramente, más de medio siglo al servicio de nuestro país y más de tres décadas al servicio de Codelco.\n",
      "\n",
      " \n",
      "\n",
      "Yo sé que ha puesto talento, pero eso no es mérito propio, viene desde el Creador. Quiero apreciar y agradecer la vocación, el compromiso y la entrega que dedicó a Codelco durante estas décadas y que nos permiten hoy día estar inaugurando una nueva etapa en la vida y en la historia de Codelco.\n",
      "\n",
      " \n",
      "\n",
      "Quiero saludar también, y con mucho cariño y gratitud, a los trabajadores de Codelco que son los que con su inteligencia y su trabajo han hecho posible esta gran obra para Codelco y para Chile.\n",
      "\n",
      " \n",
      "\n",
      "Y quiero hacer una reflexión. Ayer hubo un grave accidente en el Cerro Bellavista en Valparaíso. Quiero decirles a esos seis chilenas y chilenos que perdieron sus vidas que nuestros pensamientos y nuestras oraciones están con sus familias, y, también, que está nuestro respaldo, nuestra solidaridad y nuestro apoyo.\n",
      "\n",
      " \n",
      "\n",
      "De hecho, hace casi un año, en conjunto con el Ministerio de Minería y Sernageomin, habíamos iniciado un proyecto de verificar la vulnerabilidad de las viviendas que a lo largo y ancho de nuestro país están construidas en cerros. Ese proyecto está en plena marcha y, de hecho, ya estaba trabajando en Valparaíso y en algunas regiones del Norte.\n",
      "\n",
      " \n",
      "\n",
      "Pero vamos a intensificar ese proyecto porque todavía, especialmente con las nuevas condiciones que enfrentamos del cambio climático y el calentamiento global, hay muchas viviendas en nuestro país que son vulnerables y que ponen en riesgo las vidas de nuestros compatriotas.\n",
      "\n",
      " \n",
      "\n",
      "Hoy es un día importante para Codelco. Pocas empresas en el mundo han tenido que reinventarse en forma tan profunda y tan rápida como lo ha hecho Codelco en los últimos tiempos. Esto se ilustra con las transformaciones que están experimentando El Teniente, Andina, El Salvador y también Chuquicamata. Porque la Chuquicamata que conocimos era la Chuquicamata del siglo pasado, la Chuquicamata que estamos construyendo y el Codelco que estamos construyendo es el Codelco y Chuquicamata del siglo XXI.\n",
      "\n",
      " \n",
      "\n",
      "Y eso va a exigir mucha creatividad, mucha fuerza, mucha voluntad y mucha perseverancia porque siempre hay fuerzas que se oponen a los cambios.\n",
      "\n",
      " \n",
      "\n",
      "Pero en un mundo en que el cambio es la única constante, el riesgo más peligroso es la obsolescencia y es muy fácil caer en la obsolescencia en un mundo que cambia con tanta velocidad y nadie está exento de ese riesgo y de ese peligro. Por eso, Codelco tiene que reinventarse todos los días.\n",
      "\n",
      " \n",
      "\n",
      "Y lo que estamos haciendo hoy día de inaugurar una mina subterránea que reemplaza lo que fue la mina a tajo abierto más grande del mundo por la mina subterránea más moderna del mundo, es parte de ese proceso de cambio, de innovación que es una exigencia a la cual nadie puede restarse.\n",
      "\n",
      " \n",
      "\n",
      "Este proyecto le va a dar 40 años más de vida a Chuquicamata y quizás más, que se suman a los 104 años que ya conocemos de la historia de esta mina.\n",
      "\n",
      " \n",
      "\n",
      "Este proyecto requirió un esfuerzo gigantesco, no solamente 5 mil millones de dólares de inversión, sino que un esfuerzo en ingeniería, en diseño, en creatividad, en sintonía con la comunidad, en adaptarse a los nuevos tiempos, en asumir las nuevas exigencias.\n",
      "\n",
      " \n",
      "\n",
      "De hecho, ésta es una mina que va a significar un ejemplo. Hay muy pocas minas subterráneas de esta magnitud en el mundo. De hecho, conocemos que algunas de ellas están en Australia y son de una dimensión mucho menor. Y, por tanto, aquí estamos en la vanguardia, estamos haciendo historia al construir esta moderna mina subterránea de Chuquicamata.\n",
      "\n",
      " \n",
      "\n",
      "Cuando uno se entera de que la mina El Teniente tiene más de 4 mil kilómetros de túneles, que es prácticamente la extensión de Chile y se informa, como nos informaron el Presidente del Directorio y el Presidente Ejecutivo de lo que significa este proyecto, uno se da cuenta que en Chile somos capaces de hacer grandes cosas.\n",
      "\n",
      " \n",
      "\n",
      "Porque lo que se ha tenido que hacer aquí en materia de creatividad, imaginación, ingeniería, tecnología, aunar voluntades para poder desarrollar este proyecto demuestra que los chilenos somos capaces, cuando trabajamos unidos, de alcanzar las más altas cumbres. Pero también sabemos que cuando nos dividimos en luchas fratricidas, muchas veces, también logramos nuestras más amargas derrotas.\n",
      "\n",
      " \n",
      "\n",
      "Por eso, ésta es una operación que va a tener efectos muy importantes que ya los mencionaron los Presidentes en materia de productividad, en materia de contaminación, en materia de ahorro de energía y, por tanto, es un salto adelante, no solamente en las 140 mil toneladas diarias, sino que en la nueva forma de producir.\n",
      "\n",
      " \n",
      "\n",
      "Porque lo cierto es que estamos enfrentando exigencias distintas a las que conocíamos. La minería del pasado ya no es posible; esa minería que no respetaba suficientemente el medio ambiente, que no respetaba suficientemente las comunidades es una minería que ya pertenece al pasado. La nueva minería tiene exigencias mucho más grandes, pero también tiene aliados muy poderosos, la imaginación, la creatividad, la revolución tecnológica, la sociedad digital son los grandes aliados que tienen que acompañarnos en esta transformación de Chuquicamata, de Codelco y de nuestro país.\n",
      "\n",
      " \n",
      "\n",
      "Además de eso, Codelco tiene también por delante muchos nuevos proyectos. Tiene grandes proyectos como es el caso del nuevo nivel de la mina El Teniente; es curioso porque en la vida cuando a las personas les va bien ascienden, en la minería cuando a las empresas les va bien descienden, cada vez más profundo a buscar los minerales en las entrañas de la tierra. Ésa es la forma de vida en la minería.\n",
      "\n",
      " \n",
      "\n",
      "Y existen proyectos muy importantes como el nuevo nivel de El Teniente, la ampliación de Andina, la nueva explotación en El Salvador con un mineral nuevo, la mina subterránea de Chuquicamata, la expansión de Radomiro Tomic. Codelco tiene lleno de oportunidades y lleno de desafíos el camino del futuro.\n",
      "\n",
      " \n",
      "\n",
      "Y por eso, quiero decirle al Presidente Ejecutivo que asume en unos días, que la historia no termina con esta mina subterránea de Chuquicamata, la historia se renueva permanentemente y los desafíos van creciendo con el tiempo y, por tanto, espero que aprenda de las canas de Don Nelson y que a partir de ese conocimiento y esa sabiduría más lo que usted puede aportar, podamos escribir juntos las páginas más luminosas en la historia de Codelco.\n",
      "\n",
      " \n",
      "\n",
      "Pero también hay nuevos desafíos. Vamos a tener que hacernos cargo de una forma distinta del tratamiento de los relaves, vamos a tener que incorporar las nuevas tecnologías a un ritmo más rápido de lo que lo hemos hecho, vamos a tener que hacernos cargo de la seguridad de los trabajadores.\n",
      "\n",
      " \n",
      "\n",
      "En algunas semanas más vamos a celebrar el Día de la Seguridad Minera y va a coincidir con el día en que los chilenos nos unimos y sorprendimos al mundo entero rescatando vivos a los 33 mineros que habían quedado cautivos y atrapados en la mina San José, en el desierto más seco del mundo como es Atacama.\n",
      "\n",
      " \n",
      "\n",
      "Vamos a tener que hacernos cargo con mejores instrumentos y con mayor sensibilidad de la protección del medio ambiente. Y también vamos a tener que mejorar la productividad de Codelco.\n",
      "\n",
      " \n",
      "\n",
      "Codelco está en el tercer cuartil de productividad. Y el desafío y el compromiso que tenía el actual Presidente Ejecutivo y que tendrá el nuevo Presidente Ejecutivo es pasar del tercer al segundo cuartil en materia de productividad. Y eso es un desafío muy grande que va a requerir la contribución de todos: del Presidente Ejecutivo, del directorio, de los trabajadores, de los ingenieros, de la ciencia y de la tecnología.\n",
      "\n",
      " \n",
      "\n",
      "Por eso, Chile es un país que siempre ha tenido una vocación minera; la tuvo desde la Colonia, la tuvo desde antes de la Colonia. Ya nuestros pueblos originarios conocieron lo que era el valor de la tierra y aprendieron a extraer los minerales desde las entrañas de la tierra y esa vocación nos ha acompañado durante nuestra historia y nos va a seguir acompañando.\n",
      "\n",
      " \n",
      "\n",
      "Y, por eso, siendo Chile un país minero, una actividad que aporta, no solamente el 10% del Producto, aporta también cerca de 230 mil empleos directos, pero que, además de eso, genera una gran actividad en torno a la actividad central de la minería, es un país que tiene que reconocer su vocación minera, pero tiene que adecuar su vocación minera a las necesidades y a las exigencias de los tiempos modernos y de los chilenos de hoy.\n",
      "\n",
      " \n",
      "\n",
      "Por esa razón, estamos trabajando en buscar fórmulas que nos permitan sacar lo mejor de cada uno de nuestros compatriotas y, en consecuencia, poder avanzar en la compatibilización entre el mundo del trabajo, pero también con el mundo de la familia, el mundo del tiempo libre, de la cultura, del deporte, de la recreación o de las cosas a las cuales queremos dedicar nuestro tiempo.\n",
      "\n",
      " \n",
      "\n",
      "Y, por eso, estamos impulsando, con mucha fuerza, un proyecto que junto con reducir la jornada de trabajo introduce flexibilidad para que la jornada no sea rígida, no sea una camisa de fuerza, sino que pueda acordarse entre empleadores y trabajadores para atender mejor a las necesidades de los trabajadores.\n",
      "\n",
      " \n",
      "\n",
      "Algunos querrán trabajar más durante los primeros cuatro días de la semana y tener un fin de semana más largo, otros querrán trabajar más durante la época de invierno y tener más tiempo libre en la época de primavera. Las empresas también tienen un ciclo productivo y, a veces, requieren más trabajo en la época en que la demanda está alcanzando sus niveles máximos.\n",
      "\n",
      " \n",
      "\n",
      "Y, por tanto, la flexibilidad es lo que va a permitir que la reducción de la jornada de trabajo vaya acompañada de un aumento de la productividad y, en consecuencia, no afecte ni los niveles de empleo, ni los niveles de salarios. Ése es el proyecto que estamos impulsando.\n",
      "\n",
      " \n",
      "\n",
      "Y esto nos va a permitir que todos los sectores puedan adecuar mejor la legislación laboral a sus propias realidades. La minería tiene una realidad muy especial en materia de jornada de trabajo, queremos facilitar que esa realidad se pueda expresar en jornadas más libres y más flexibles, siempre cuidando, y con mucha atención y celo, los legítimos intereses de los trabajadores.\n",
      "\n",
      " \n",
      "\n",
      "Pero quiero decir que la flexibilidad no es sinónimo de precariedad, como algunos lo entienden equivocadamente, la flexibilidad es sinónimo de inteligencia, la flexibilidad puede reemplazar a la rigidez con acuerdos inteligentes entre las partes en que todos ganan y ése es el concepto central.\n",
      "\n",
      " \n",
      "\n",
      "Quisiera terminar estas palabras reconociendo que el mundo está viviendo tiempos difíciles. Veamos cómo se ha debilitado la economía mundial, cómo el comercio mundial está cayendo –no es que esté creciendo menos, está cayendo, está disminuyendo–, cómo las dos principales economías de nuestro continente están en recesión, cómo nos enteramos que grandes potencias económicas europeas como Francia y Alemania también están en recesión.\n",
      "\n",
      " \n",
      "\n",
      "Y, en consecuencia, hoy más que nunca tenemos que hacer un gran esfuerzo para mantener a Chile en marcha. Chile está creciendo, está creando empleos, está mejorando los salarios, está aumentando la productividad. Pero en tiempos difíciles es cuando más se requiere la unidad de los chilenos.\n",
      "\n",
      " \n",
      "\n",
      "Por eso, yo quiero convocar a todos mis compatriotas a que unamos fuerzas para mantener a Chile en marcha con un solo norte: darles a todos nuestros compatriotas la oportunidad de desarrollar sus talentos, la seguridad de una vida con dignidad y la oportunidad de tener una vida más plena y más feliz. Y este proyecto de Chuquicamata Subterráneo es un aporte a mantener a Chile en marcha.\n",
      "\n",
      " \n",
      "\n",
      "Y, por eso, termino, una vez más, agradeciendo a los trabajadores de Codelco, a los trabajadores de Chuquicamata y a los trabajadores de nuestra patria.\n",
      "\n",
      " \n",
      "\n",
      "Muchas gracias.\n"
     ]
    }
   ],
   "source": [
    "print(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fab6ef-cfac-4905-8d76-7bc77004dd06",
   "metadata": {},
   "source": [
    "Del texto anterior, se puede efectuar la función **resumir_texto(texto, lineas=0)**, que tiene por objeto efectuar el resumen del discurso seleccionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73feeea",
   "metadata": {
    "id": "f73feeea"
   },
   "outputs": [],
   "source": [
    "def resumir_texto(texto, lineas=0):\n",
    "    nlp_text=nlp(texto)\n",
    "    oraciones=[]\n",
    "    for sent in nlp_text.doc.sents:\n",
    "        oraciones.append(str(sent).replace('\\xa0','').replace('\\n',''))\n",
    "    oraciones_new=[EliminaNumeroYPuntuacion(Lematizar(oracion)) for oracion in oraciones]\n",
    "    features = [ObtenerEmbeddingOracion(modeloLSA, dim, oracion) for oracion in oraciones_new]\n",
    "    features = np.array(features)\n",
    "    print(f\"El texto contiene {len(features)} parrafos\")\n",
    "    if lineas==0 or lineas<0:\n",
    "        resumen=int(len(features)/2)\n",
    "    else:\n",
    "        resumen=lineas\n",
    "    print(f\"Se escogerán {resumen} parrafos para el resumen\")\n",
    "    similitudes = []\n",
    "    vector_promedio= features.mean(axis=0)\n",
    "    for feature in features: \n",
    "        similitud = 1-cosine(vector_promedio,feature)\n",
    "        similitudes.append(similitud)\n",
    "    print(f\"Las similitudes encontradas son \\n\" + '\\n'.join([str(x) for x in similitudes]))\n",
    "    df = pd.DataFrame({'oraciones':oraciones, 'oraciones_new':oraciones_new, 'similitudes':similitudes})\n",
    "    resumen_texto = [x for x in df.sort_values(by='similitudes').head(11).sort_index()['oraciones']]\n",
    "    return resumen_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828dc0ba",
   "metadata": {
    "id": "828dc0ba",
    "outputId": "615ca55a-38b0-4608-c81f-62bb1449d06d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto contiene 67 parrafos\n",
      "Se escogerán 33 parrafos para el resumen\n",
      "Las similitudes encontradas son \n",
      "0.9880419673597625\n",
      "0.9965828826723953\n",
      "0.9922742256646414\n",
      "0.9992838071453902\n",
      "0.9984959554441492\n",
      "0.9650700076724696\n",
      "0.9956432115877422\n",
      "0.9779236123022733\n",
      "0.9979752744762229\n",
      "0.9868167365300226\n",
      "0.9990039924624349\n",
      "0.9792802865648855\n",
      "0.9968020465266652\n",
      "0.9981745689073785\n",
      "0.9980037713907138\n",
      "0.9913495249225481\n",
      "0.9994164369698021\n",
      "0.9942955131380974\n",
      "0.9986903918321726\n",
      "0.9985647330866468\n",
      "0.9983794378778291\n",
      "0.9920432223806239\n",
      "0.997056728246864\n",
      "0.9957062826834518\n",
      "0.9976021335623573\n",
      "0.9994748987374275\n",
      "0.9987270140559512\n",
      "0.9837070435079452\n",
      "0.998874255349748\n",
      "0.9919748040069074\n",
      "0.996373751940081\n",
      "0.9994068927113317\n",
      "0.9922608109973905\n",
      "0.9981853349328861\n",
      "0.99837952346809\n",
      "0.9964845057893102\n",
      "0.9939837420197674\n",
      "0.9997438702546185\n",
      "0.9530649248186409\n",
      "0.9992760665412908\n",
      "0.9985865661754786\n",
      "0.9978581755186137\n",
      "0.9990000920389475\n",
      "0.9963914718777223\n",
      "0.9991285209582269\n",
      "0.9978124665998798\n",
      "0.9975536224386018\n",
      "0.9986587773165169\n",
      "0.999665012950171\n",
      "0.9981924353597635\n",
      "0.9994903755854312\n",
      "0.9975290514834005\n",
      "0.9988065750075736\n",
      "0.998571800261822\n",
      "0.9957663155071863\n",
      "0.9977369967982936\n",
      "0.9993666502399982\n",
      "0.9992756931924714\n",
      "0.9969702323607327\n",
      "0.9980024520026018\n",
      "0.98757048219642\n",
      "0.9942560822198867\n",
      "0.9990727442580795\n",
      "0.9985762518285929\n",
      "0.9930764942476868\n",
      "0.9960169991363221\n",
      "0.918966368969562\n"
     ]
    }
   ],
   "source": [
    "resumen=resumir_texto(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5d1d5",
   "metadata": {
    "id": "92e5d1d5",
    "outputId": "7ff7b9e5-7939-4fb3-bc9e-0f7ca432438f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muy buenas tardes:Señor Ministro, señor Intendente, señor Senador, señor Presidente del Directorio, señor Alcalde; y quiero entregar un saludo muy especial a Nelson Pizarro, Presidente Ejecutivo de Codelco.\n",
      "Y quiero hacer una reflexión.\n",
      "Quiero decirles a esos seis chilenas y chilenos que perdieron sus vidas que nuestros pensamientos y nuestras oraciones están con sus familias, y, también, que está nuestro respaldo, nuestra solidaridad y nuestro apoyo.\n",
      "Ese proyecto está en plena marcha y, de hecho, ya estaba trabajando en Valparaíso y en algunas regiones del Norte.\n",
      "Hoy es un día importante para Codelco.\n",
      "Y eso va a exigir mucha creatividad, mucha fuerza, mucha voluntad y mucha perseverancia porque siempre hay fuerzas que se oponen a los cambios.\n",
      "Pero también sabemos que cuando nos dividimos en luchas fratricidas, muchas veces, también logramos nuestras más amargas derrotas.\n",
      "Porque lo cierto es que estamos enfrentando exigencias distintas a las que conocíamos.\n",
      "Pero también hay nuevos desafíos.\n",
      "Y, en consecuencia, hoy más que nunca tenemos que hacer un gran esfuerzo para mantener a Chile en marcha.\n",
      "Muchas gracias.\n"
     ]
    }
   ],
   "source": [
    "print( '\\n'.join(resumen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dea30e-7038-4aca-86e5-df216aa75873",
   "metadata": {
    "id": "b5f9092b"
   },
   "source": [
    "## Referencias:\n",
    "- https://es.wikipedia.org/wiki/Word_embedding\n",
    "- https://iq.opengenus.org/gaussian-naive-bayes/\n",
    "- https://jonathan-hui.medium.com/machine-learning-singular-value-decomposition-svd-principal-component-analysis-pca-1d45e885e491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fa137-ceee-4f21-abf0-7b13cbb28b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
